{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contributed by:\n",
    "\n",
    "Tobias Rasse\n",
    "Max Planck Institute for Heart and Lung Research\n",
    "61231 Bad Nauheim, Germany\n",
    "tobias.rasse@mpi-bn.mpg.de\n",
    "\n",
    "Images recorded by:\n",
    "Tobias Rasse with a Samsung Galaxy S6 Active Smartphone,\n",
    "CC-BY 4.0 Licence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General description of OpSeF\n",
    "\n",
    "The analysis pipeline consists of four principle sets of functions to import and reshape the data, to pre-process it, to segment it and to analyze and classify results.\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_M1.jpg\" alt = \"Paper Fig M1\" style = \"width: 500px;\"/>\n",
    "\n",
    "OpSeF is designed such that parameter for pre-processing and selection of the ideal model for segmentation are one functional unit. \n",
    "\n",
    "We recommend a iterative optimization, that starts with a large number of model, and relatively few, but conceptually distinct preprocessing pipelines, to the lower then the number of model to be explored while fine-tuning the most pre-processing pipeline, e.g. by optimizing filter kernel or the way how histograms are equalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the parameter tuning process for the cobblestons demo dataset\n",
    "\n",
    "The parameter tuning was performed as described below:\n",
    "\n",
    "First minor smooting (median filter with 3x3 kernel) (Input_000) and moderate background substration was applied. Next, the effect of additional histogram equalization (Input_001), edge enhancement (Input 002), and image inversion (Input 003) was tested.\n",
    "\n",
    "All available model were tested, the Cellposescale factor range 0.2,0.4,0.6 was explored.\n",
    "\n",
    "### Run 1:\n",
    "\n",
    "The Cellpose Cyto model withscale factor = 0.4 & Input 3 produced without further optimzation a goods result in both test images. Outlines are well defined, no objects were missed, none oversegemented (Fig 1 A & B). \n",
    "\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_R1_AB.jpg\" alt = \"Result Run001\" style = \"width: 700px;\"/>\n",
    "\n",
    "Input 0 gave a simlar good results (data not shown), but one stone was misssed in one of the two images.\n",
    "\n",
    "#### => check how well the CP cyto model withscale factor = 0.4 & Input 3 performs on all images\n",
    "\n",
    "### Run 2:\n",
    "The model works well. Outlines are well defined.Cellpose has been trained on a large variety of images and had been reported to perform well on  objects of similar shape (Fig S1 adapted from Fig 4 Stringer et. al.).\n",
    "\n",
    "<img src=\"./Figures_Demo/cobblestones_S1_CP_Fig4.jpg\" alt = \"Fig S1\" style = \"width: 700px;\"/>\n",
    "\n",
    "Only in one image three objects were missed and one is oversegemented. Borders around these stones are very hard to observe and even further training might not resolve such extreme difficult segmentation tasks Fig 1 E,F.\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_R1_CF.jpg\" alt = \"Result Run002\" style = \"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Core-Settings that shall not be changed\n",
    "Please use OpSef_Configure_XXX to change these global settings.\n",
    "Changes in this file only necessary to intergrate new model,\n",
    "or to change the aut-ogenerated folderstructure.\n",
    "Changes to the folderstructure might cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processing pipeline from ./my_runs/main_settings.pkl\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./my_runs/main_settings.pkl\"\n",
    "infile = open(file_path,'rb')\n",
    "parameter = pickle.load(infile)\n",
    "print(\"Loading processing pipeline from\",file_path)\n",
    "infile.close()\n",
    "model_dic,folder_structure = parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define General Parameter\n",
    "most parameter define the overall processing and likeley do not change between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that determine the processing pipeline and (generally) do not change between runs\n",
    "\n",
    "pc = {}\n",
    "\n",
    "#################\n",
    "## Basic ########\n",
    "#################\n",
    "\n",
    "pc[\"sub_f\"] = folder_structure # these folder will be auto-generated\n",
    "pc[\"batch_size\"] = 2 # the number of images to be quantified must be a multiple of batchscale factor (for segmentation)\n",
    "                     # extract the properties (below) from region_props\n",
    "pc[\"get_property\"] = [\"label\",\"area\",\"centroid\", \"eccentricity\", \n",
    "                      \"equivalent_diameter\",\"mean_intensity\",\"max_intensity\",\n",
    "                      \"min_intensity\",\"perimeter\"]\n",
    "pc[\"naming_scheme\"] = \"Simple\"        # or \"Simple\" Export_ZSplit\" to create substacks \n",
    "\n",
    "###############################\n",
    "# Define use of second channel\n",
    "###############################\n",
    "\n",
    "pc[\"export_another_channel\"] = False  # export other channel (to create a mask or for quantification) ?\n",
    "if [\"export_another_channel\"]:\n",
    "    pc[\"create_filter_mask_from_channel\"] = False # use second channel to make a mask?\n",
    "    pc[\"Quantify_2ndCh\"] = False      # shall this channel be quantified?\n",
    "    if pc[\"Quantify_2ndCh\"]:\n",
    "        pc[\"merge_results\"] = True    # shall the results of the two intensity quantification be merged \n",
    "                                     # (needed for advanced plotting)\n",
    "        pc[\"plot_merged\"] = True     # plot head of dataframe in notebook ?\n",
    "\n",
    "################################\n",
    "# Define Analysis & Plotting ###\n",
    "################################\n",
    "\n",
    "pc[\"Export_to_CSV\"] = False # shall results be exported to CSV (usually only true for the final run)\n",
    "if pc[\"Export_to_CSV\"]:\n",
    "    pc[\"Intensity_Ch\"] = 999 # put 999 if data contains only one channel\n",
    "    pc[\"Plot_Results\"] = True # Do you want to plot results ?\n",
    "    pc[\"Plot_xy\"] = [[\"area\",\"mean_intensity\"],[\"area\",\"circularity\"]] # Define what you want to plot (x/y)\n",
    "    pc[\"plot_head_main\"] = True # plot head of dataframe in notebook ?\n",
    "    pc[\"Do_ClusterAnalysis\"] = False # shall cluster analysis be performed? \n",
    "    if pc[\"Do_ClusterAnalysis\"]: # Define (below) which values will be included in the TSNE:\n",
    "        pc[\"include_in_tsne\"] = [\"area\",\"eccentricity\",\"equivalent_diameter\",\n",
    "                                 \"mean_intensity\",\"max_intensity\",\"min_intensity\",\"perimeter\"]\n",
    "        pc[\"cluster_expected\"] = 4 # How many groups/classes do you expected?\n",
    "        pc[\"tSNE_learning_rate\"] = 100 # Define learning rate\n",
    "        pc[\"link_method\"] = \"ward\" # or \"average\", or \"complete\", or \"single\" details see below\n",
    "else:\n",
    "    pc[\"Plot_Results\"] = False\n",
    "    pc[\"Do_ClusterAnalysis\"] = False \n",
    "    \n",
    "pc[\"toFiji\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here input & basic processing that (generally) does not change between runs\n",
    "\n",
    "input_def = {}\n",
    "input_def[\"root\"] = \"/home/trasse/Desktop/MLTestData/cobblestones_test\" # define folder where images are located\n",
    "input_def[\"dataset\"] = \"cobble_stones_512\" # give the dataset a common name\n",
    "input_def[\"mydtype\"] = np.uint8 # bit depth of input images\n",
    "\n",
    "input_def[\"input_type\"] = \".tif\" # or .tif\n",
    "if input_def[\"input_type\"] == \".tif\":\n",
    "    input_def[\"is3D\"] = False # is the data 3D or 2D ???\n",
    "elif input_def[\"input_type\"] == \".lif\":\n",
    "    input_def[\"rigth_size\"] = (2048,2048) \n",
    "    input_def[\"export_single_ch\"] = 99   # which channel to extract from the lif file (if only one)\n",
    "\n",
    "input_def[\"split_z\"] = False # chose here to split z-stack into multiple substacts to avoid that cells fuse after projection\n",
    "if input_def[\"split_z\"]:# choosen, define:\n",
    "    input_def[\"z_step\"] = 3 #scale factor of substacks\n",
    "    if input_def[\"input_type\"] == \".lif\":\n",
    "        input_def[\"export_multiple_ch\"] = [0,1] # channels to be exported\n",
    "    \n",
    "\n",
    "#########################################################################\n",
    "## the following options are only implemented with Tiff files as input ##\n",
    "#########################################################################\n",
    "\n",
    "input_def[\"toTiles\"] = False\n",
    "if input_def[\"toTiles\"]:\n",
    "    input_def[\"patch_size\"] = (15,512,512)\n",
    "\n",
    "input_def[\"bin\"] = False \n",
    "if input_def[\"bin\"]:\n",
    "    input_def[\"bin_factor\"] = 2 # same for x/y\n",
    "\n",
    "# coming soon...\n",
    "input_def[\"n2v\"] = False\n",
    "input_def[\"CARE\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter for export (if needed)\n",
    "\n",
    "if pc[\"export_another_channel\"]:\n",
    "    input_def[\"post_export_single_ch\"] = 0                   # which channel to extract from the lif file\n",
    "    input_def[\"post_subset\"] = [\"09_Ch_000_CS985\"]          # analyse these intensity images\n",
    "    if pc[\"Quantify_2ndCh\"]:\n",
    "        pc[\"Intensity_2ndCh\"] = input_def[\"post_export_single_ch\"]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "# in this dictionary all settings for the model are stored\n",
    "initModelSettings = {}\n",
    "# Variables U-Net Cellprofiler\n",
    "initModelSettings[\"UNet_model_file_CP01\"] = \"./model_Unet/UNet_CP001.h5\"\n",
    "initModelSettings[\"UNetShape\"] = (512,512)\n",
    "initModelSettings[\"UNetSettings\"] = [{\"activation\": \"relu\", \"padding\": \"same\"},{ \"momentum\": 0.9}]\n",
    "# Variables StarDist\n",
    "initModelSettings[\"basedir_StarDist\"] = \"./model_stardist\"\n",
    "# Variables Cellpose\n",
    "initModelSettings[\"Cell_Channels\"] = [[0,0],[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Runs\n",
    "\n",
    "These parameter listed below are likely change between runs.\n",
    "\n",
    "Preprocessing is mainly based on scikit-image.\n",
    "\n",
    "Segmentation in cooperates the pre-trained U-Net implementation used in Cellprofiler 3.0, the StarDist 2D model and Cellpose.\n",
    "\n",
    "Importantly, OpSeF is designed such that parameter for pre-processing and selection of the ideal model for segmentation are one functional unit.\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_M4.jpg\" alt = \"Paper Fig M4\" style = \"width: 500px;\"/>\n",
    "\n",
    "The above show Figure illustrates this concept with a processing pipeline, in three different models are applied to four different pre-processing pipelines each. Next, the resulting images are classified into results that are largely correct or suffer from failure to detect objects, under- or over-segmentation. In the given example, pre-processing pipeline three and model two seem to give overall the best result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define variable that might change in each run\n",
    "\n",
    "run_def = {}\n",
    "run_def[\"display_base\"] = \"000\" # defines the image used as basis for the overlay. See documemtation for details.\n",
    "run_def[\"run_ID\"] = \"002\" #give each run a new ID (unless you want to overwrite the old data)\n",
    "run_def[\"clahe_prm\"] = [(18,18),3] # Parameter for CLAHE\n",
    "\n",
    "# Run 1\n",
    "input_def[\"subset\"] = [\"Train\"] # filter by name\n",
    "\n",
    "# Run 2\n",
    "input_def[\"subset\"] = [\"All\"] # filter by name\n",
    "\n",
    "#########################\n",
    "# Define preprocessing ##\n",
    "#########################\n",
    "\n",
    "\n",
    "# Run1\n",
    "run_def[\"pre_list\"] = [[\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",False],\n",
    "                       [\"Median\",3,50,\"Max\",True,run_def[\"clahe_prm\"],\"no\",False],\n",
    "                       [\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"sobel\",False],\n",
    "                       [\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",True]]\n",
    "\n",
    "# Run2\n",
    "run_def[\"pre_list\"] = [[\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",True]]\n",
    "\n",
    "\n",
    "# For Cellpose\n",
    "\n",
    "run_def[\"rescale_list\"] = [0.2,0.4,0.6] # run1\n",
    "run_def[\"rescale_list\"] = [0.4] # run2\n",
    "\n",
    "# Define model\n",
    "\n",
    "run_def[\"ModelType\"] = [\"CP_nuclei\",\"CP_cyto\",\"SD_2D_dsb2018\",\"UNet_CP001\"] # run1\n",
    "run_def[\"ModelType\"] = [\"CP_cyto\"]  # run2\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Define postprocessing & filtering                       #\n",
    "# keep only the objects within the defined ranges         #\n",
    "###########################################################\n",
    "\n",
    "# (same for all runs) \n",
    "run_def[\"filter_para\"] = {}\n",
    "run_def[\"filter_para\"][\"area\"] = [0,10000]\n",
    "run_def[\"filter_para\"][\"perimeter\"] = [0,99999999]\n",
    "run_def[\"filter_para\"][\"circularity\"] = [0,1] # (equivalent_diameter * math.pi) / perimeter\n",
    "run_def[\"filter_para\"][\"mean_intensity\"] = [0,65535]\n",
    "run_def[\"filter_para\"][\"sum_intensity\"] = [0,100000000000000]\n",
    "run_def[\"filter_para\"][\"eccentricity\"] = [0,10]\n",
    "\n",
    "############################################################################\n",
    "# settings that are only needed if condition below is met which means you  #\n",
    "# plan to use a mask from a second channel to filter results               #\n",
    "############################################################################\n",
    "\n",
    "if pc[\"create_filter_mask_from_channel\"]:\n",
    "    run_def[\"binary_filter_mp\"] = [[\"open\",5,2,1,\"Morphology\"],[\"close\",5,3,1,\"Morphology\"],[\"erode\",5,1,1,\"Morphology\"]]\n",
    "    run_def[\"para_mp\"] = [[\"Mean\",5],[0.6],run_def[\"binary_filter_mp\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to reproduce these results?\n",
    "\n",
    "The notebook is set up to reproduce the results of the last run (Run 2)\n",
    "\n",
    "The execute previous runs please delete or commented out settings used for Run 2 \n",
    "\n",
    "Settings are saved in a .pkl file.\n",
    "\n",
    "The next cell prints the filepath & name of this file.\n",
    "\n",
    "OpSef_Run_XXX loads the settings specified above and processed all images.\n",
    "The only change you have to make within OpSef_Run_XXX  is specifying the location\n",
    "of this setting file.\n",
    "\n",
    "## Save Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please execute this file with OPsef_Run_XXX ./Demo_Notebooks/my_runs/Parameter_cobble_stones_512_Run_002.pkl\n"
     ]
    }
   ],
   "source": [
    "#  auto-create parameter set from input above\n",
    "run_def[\"run_now_list\"] = [model_dic[x] for x in run_def[\"ModelType\"]]\n",
    "parameter = [pc,input_def,run_def,initModelSettings]\n",
    "\n",
    "# save it\n",
    "file_name = \"./my_runs/Parameter_{}_Run_{}.pkl\".format(input_def[\"dataset\"],run_def[\"run_ID\"])\n",
    "file_name_load = \"./Demo_Notebooks/my_runs/Parameter_{}_Run_{}.pkl\".format(input_def[\"dataset\"],run_def[\"run_ID\"])\n",
    "print(\"Please execute this file with OPsef_Run_XXX\",file_name_load)\n",
    "outfile = open(file_name,'wb')\n",
    "pickle.dump(parameter,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Folderstructure    ####\n",
    "\n",
    "input_def[\"root\"] = \"/home/trasse/Desktop/MLTestData/leaves\" # defines the main folder \n",
    "\n",
    "# Put files in these subfolder\n",
    "# .lif\n",
    "# root/myimage_container.lif\n",
    "# root/tiff/myimage1.tif (in case this folder is the direct input to the pre-processing pipeline)\n",
    "#          /myimage2.tif ...\n",
    "# or\n",
    "# root/tiff_raw_2D/myimage1.tif (if you want to make patches in 2D)\n",
    "# root/tiff_to_split/myimage1.tif (if you want ONLY create substacts, bt not BIN or patch before)\n",
    "# root/tiff_raw/myimage1.tif (for all pipelines that start with patching or binning and use stacks)\n",
    "\n",
    "\n",
    "######################################\n",
    "### What is a display base image ????\n",
    "######################################\n",
    "\n",
    "run_def[\"display_base\"]\n",
    "''' \n",
    "display base is ideally set to \"same\".\n",
    "in this case the visualiation of segmentation border will be\n",
    "drawn on top of the input image to the segmentation\n",
    "If this behavior is not desired a three digit number\n",
    "that refers to the position in the run_def[\"pre_list\"] might to be entered.\n",
    "example:\n",
    "run_def[\"pre_list\"] = [[\"Median\",3,8,\"Sum\",True,clahe_prm],[\"Mean\",5,3,\"Max\",True,clahe_prm]]\n",
    "& the image resulting from:\n",
    "[\"Mean\",5,3,\"Max\",True,clahe_prm]\n",
    "shall be used as basis for display:\n",
    "then set: \n",
    "run_def[\"display_base\"] = \"001\"\n",
    "'''\n",
    "\n",
    "##########################\n",
    "# Parameter for Cellpose:\n",
    "##########################\n",
    "\n",
    "# Define: \n",
    "# initModelSettings[\"Cell_Channels\"] \n",
    "# to run segementation on grayscale=0, R=1, G=2, B=3\n",
    "# initModelSettings[\"Cell_Channels\"] = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "initModelSettings[\"Cell_Channels\"] = [[0,0],[0,0]]\n",
    "\n",
    "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "initModelSettings[\"Cell_Channels\"] = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "initModelSettings[\"Cell_Channels\"] = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
    "initModelSettings[\"Cell_Channels\"] = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "\n",
    "# if rescale is set to None, thescale factor of the cells is estimated on a per image basis\n",
    "# if you want to set thescale factor yourself, set it to 30. / average_cell_diameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is mainly based on scikit-image. It consist of a linear pipeline:\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_M3.jpg\" alt = \"Paper Fig M3\" style = \"width: =800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "## Variables for Preprocessing\n",
    "#####################################\n",
    "\n",
    "## The list \n",
    "\n",
    "run_def[\"pre_list\"]\n",
    "\n",
    "#is organized (as illustrated above) organized in the following way:\n",
    "\n",
    "# (1) Filter type\n",
    "# (2) Kernel\n",
    "# (3) substract fixed value\n",
    "# (4) projection type\n",
    "# (5) calhe enhance (Yes/No) as defined above\n",
    "# (6) Calhe parameter\n",
    "# (7) enhance edges (and how) (no, roberts, sobel)\n",
    "# (8) invert image\n",
    "\n",
    "# It is a list of lists, each entry defines one pre-processing pipeline:\n",
    "\n",
    "# e.g.\n",
    "# Run1\n",
    "run_def[\"pre_list\"] = [[\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",False],\n",
    "                       [\"Median\",3,50,\"Max\",True,run_def[\"clahe_prm\"],\"no\",False],\n",
    "                       [\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"sobel\",False],\n",
    "                       [\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link analysis (Settings from t-SNE)\n",
    "\n",
    "from https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "linkage{“ward”, “complete”, “average”, “single”}\n",
    "\n",
    "Which linkage criterion to use:\n",
    "\n",
    "The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.\n",
    "\n",
    "ward minimizes the variance of the clusters being merged. average uses the average of the distances of each observation of the two sets. complete or maximum linkage uses the maximum distances between all observations of the two sets.\n",
    "\n",
    "single uses the minimum of the distances between all observations of the two sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
